

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lecture 7: CNNs in Practice &#8212; DSCI 572 Supervised Learning II</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/07_cnns-pt2';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 8: Advanced Convolutional Models" href="08_advanced-deep-learning.html" />
    <link rel="prev" title="Lecture 6: Introduction to Convolutional Neural Networks" href="06_cnns-pt1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/mds-hex-sticker.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/mds-hex-sticker.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_floating-point-numbers.html">Lecture 1: Floating-Point Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_gradient-descent.html">Lecture 2: Optimization &amp; Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_sgd-intro-to-nn.html">Lecture 3: Stochastic Gradient Descent and Introduction to Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_pytorch-neural-networks-pt1.html">Lecture 4: Introduction to Pytorch &amp; Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_neural-networks-pt2.html">Lecture 5: Training Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_cnns-pt1.html">Lecture 6: Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 7: CNNs in Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_advanced-deep-learning.html">Lecture 8: Advanced Convolutional Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="appendixA_gradients.html">Appendix A: Gradients Review</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendixB_logistic-loss.html">Appendix B: Logistic Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendixC_computing-derivatives.html">Appendix C: Computing Derivatives</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendixD_bitmoji-CNN.html">Appendix D: Creating a CNN to Predict Bitmojis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Attribution</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../LICENSE.html">LICENSE</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/UBC-MDS/DSCI_572_sup-learn-2" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lectures/07_cnns-pt2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 7: CNNs in Practice</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-learning-objectives">Lecture Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap">Recap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datasets-dataloaders-and-transforms">1. Datasets, Dataloaders, and Transforms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-data">1.1 Preparing Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading-pytorch-models">1.2 Saving and Loading PyTorch Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation">1.3 Data Augmentation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-batch-normalization">1.4 (Optional) Batch Normalization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">2. Hyperparameter Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-explaining-cnns">3. (Optional) Explaining CNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">4. Transfer Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pre-trained-models-out-of-the-box">4.1 Using pre-trained models out-of-the-box</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pre-trained-models-as-feature-extractors">4.2 Using pre-trained models as feature extractors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-adding-extra-layers-to-the-pre-trained-network">4.2.1 Approach 1: Adding extra layers to the pre-trained network</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-using-extracted-features-in-other-models">4.2.2 Approach 2: Using extracted features in other models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pre-trained-models-for-fine-tuning">4.3 Using pre-trained models for fine tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning-summary">4.4 Transfer Learning Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-highlights">5. Lecture Highlights</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <a class="reference internal image-reference" href="../_images/dsci572_header.png"><img alt="../_images/dsci572_header.png" src="../_images/dsci572_header.png" style="width: 600px;" /></a>
<section class="tex2jax_ignore mathjax_ignore" id="lecture-7-cnns-in-practice">
<h1>Lecture 7: CNNs in Practice<a class="headerlink" href="#lecture-7-cnns-in-practice" title="Permalink to this heading">#</a></h1>
<p><br><br><br></p>
<section id="lecture-learning-objectives">
<h2>Lecture Learning Objectives<a class="headerlink" href="#lecture-learning-objectives" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Load image data using <code class="docutils literal notranslate"><span class="pre">torchvision.datasets.ImageFolder()</span></code> to train a network in PyTorch</p></li>
<li><p>Explain what “data augmentation” is and why we might want to do it</p></li>
<li><p>Be able to save and re-load a PyTorch model</p></li>
<li><p>Tune the hyperparameters of a PyTorch model using <a class="reference external" href="https://ax.dev/">Ax</a></p></li>
<li><p>Describe what transfer learning is and the different flavours of it: “out-of-the-box”, “feature extractor”, “fine tuning”</p></li>
</ul>
<p><br><br><br></p>
</section>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">utils.plotting</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.set_seed</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !conda install -y memory_profiler</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">memory_profiler</span>
</pre></div>
</div>
</div>
</div>
<p><br><br><br></p>
</section>
<section id="recap">
<h2>Recap<a class="headerlink" href="#recap" title="Permalink to this heading">#</a></h2>
<p>A Convolutional Neural Network (CNN) is a specialized type of neural network architecture predominantly used for image classification tasks.</p>
<p><strong>The typical structure of a CNNs</strong></p>
<ul class="simple">
<li><p>Several convolutional and pooling layers:</p>
<ul>
<li><p><strong>Convolutional layers</strong> (referred to as Conv2d layers in PyTorch) use filters or kernels to capture spatial hierarchies and patterns within the data.</p></li>
<li><p><strong>Activation functions</strong> are employed to introduce non-linearities into the model.</p></li>
<li><p><strong>Pooling layers</strong> are used to reduce the spatial dimensions of the feature maps, helping in decreasing the complexity of the model.</p></li>
<li><p><strong>Dropout layers (optional)</strong> can be incorporated for regularization in order to prevent overfitting.</p></li>
</ul>
</li>
<li><p>Followed by a fully connected (dense) layer that leads to the output.</p>
<ul>
<li><p>For binary classification: Use Sigmoid activation if using <code class="docutils literal notranslate"><span class="pre">BCELoss</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Loss function</strong></p>
<ul class="simple">
<li><p>Multiclass classification: <code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code></p></li>
<li><p>Binary classification: <code class="docutils literal notranslate"><span class="pre">BCEWithLogitsLoss</span></code> loss or use Sigmoid if using <code class="docutils literal notranslate"><span class="pre">BCELoss</span></code></p></li>
<li><p>For regression: No activation and MSELoss</p></li>
</ul>
<p><strong>Parameters of the model and parameter sharing</strong></p>
<ul class="simple">
<li><p>The kernels (or filters) used in convolutional layers, along with their corresponding biases, and the weights (and biases) in the fully connected layers after flattening, constitute the parameters of the CNN model.</p></li>
<li><p>CNNs use of the same convolutional filters across the entire input, allowing the network to detect features regardless of their spatial location and significantly reducing the number of parameters. This is known as <strong>parameter sharing</strong>.</p></li>
</ul>
<p><img alt="" src="../_images/cnn_big_picture.png" /></p>
<p><a class="reference external" href="https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks">Source</a></p>
<p><br><br><br><br></p>
</section>
<section id="datasets-dataloaders-and-transforms">
<h2>1. Datasets, Dataloaders, and Transforms<a class="headerlink" href="#datasets-dataloaders-and-transforms" title="Permalink to this heading">#</a></h2>
<section id="preparing-data">
<h3>1.1 Preparing Data<a class="headerlink" href="#preparing-data" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch</span></code> and <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> provide out-of-the-box functionality for loading in lots of different kinds of data.</p></li>
<li><p>The way you create a dataloader depends on the data you have (i.e., do you have numpy arrays, tensors, images, or something else?) and the PyTorch docs <a class="reference external" href="https://pytorch.org/docs/stable/data.html#dataset-types">can help you out</a></p></li>
<li><p>Loading data into PyTorch is usually a two-step process:</p>
<ol class="arabic simple">
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">dataset</span></code> (this is your raw data)</p></li>
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">dataloader</span></code> (this will help you batch your data)</p></li>
</ol>
</li>
<li><p>Working with CNNs and images, you’ll mostly be using <code class="docutils literal notranslate"><span class="pre">torchvision.datasets.ImageFolder()</span></code> (<a class="reference external" href="https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder">docs</a>), it’s very easy to use-</p></li>
</ul>
<p><br><br><br></p>
<p>It assumes you have a directory structure with sub-directories for each class like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>data
│
├── class_1
│   ├── image_1.png 
│   ├── image_2.png
│   ├── image_3.png
│   └── etc.
└── class_2
    ├── image_1.png 
    ├── image_2.png
    ├── image_3.png
    └── etc.
</pre></div>
</div>
<p><br><br><br></p>
<ul class="simple">
<li><p>For example, consider the training dataset I have in the current directory at <code class="docutils literal notranslate"><span class="pre">lectures/data/eva_bitmoji_rgb</span></code>:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>eva_bitmoji_rgb
└── train
    ├── not_eva
    │   ├── image_1.png 
    │   ├── image_2.png
    │   ├── image_3.png
    │   └── etc.
    └── eva
        ├── image_1.png 
        ├── image_2.png
        ├── image_3.png
        └── etc.
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TRAIN_DIR</span> <span class="o">=</span> <span class="s2">&quot;data/eva_bitmoji_rgb/train/&quot;</span>

<span class="n">mem</span> <span class="o">=</span> <span class="n">memory_profiler</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">TRAIN_DIR</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memory consumed: </span><span class="si">{</span><span class="n">memory_profiler</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mem</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Memory consumed: -1 MB
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Notice how our memory usage is the same, we aren’t loading anything in yet, just making PyTorch aware of what kind of data we have and where it is</p></li>
</ul>
<p><br><br><br></p>
<ul class="simple">
<li><p>We can now check various information about our <code class="docutils literal notranslate"><span class="pre">train_dataset</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classes: </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">classes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Class count: </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Samples:&quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;First sample: </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classes: [&#39;eva&#39;, &#39;not_eva&#39;]
Class count: 1018, 1020
Samples: 2038
First sample: (&#39;data/eva_bitmoji_rgb/train/eva/Eva_10039954 copy.png&#39;, 0)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Now, we could start working with this dataset directly</p></li>
<li><p>For example, here’s the first sample:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gen</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Class: </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">classes</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">img</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Class: eva
</pre></div>
</div>
<img alt="../_images/209a174ecde89f880a1f0f6ed4e4538a28d58d6adc466014bf865a0d446bd32f.png" src="../_images/209a174ecde89f880a1f0f6ed4e4538a28d58d6adc466014bf865a0d446bd32f.png" />
</div>
</div>
<p><br><br><br></p>
<ul class="simple">
<li><p>But often we want to apply some <strong>pre-processing</strong> to our data</p></li>
<li><p>For example, <code class="docutils literal notranslate"><span class="pre">ImageFolder</span></code> loads our data using the <code class="docutils literal notranslate"><span class="pre">PIL</span></code> package, but we need tensors</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image data type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;     Image size: </span><span class="si">{</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Image data type: &lt;class &#39;PIL.Image.Image&#39;&gt;
     Image size: (199, 199)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Any pre-processing we wish to apply to our images is done using <code class="docutils literal notranslate"><span class="pre">torchvision.transforms</span></code></p></li>
<li><p>There are a lot of transformation options here, but we’ll explore some more later. For now, we’ll <code class="docutils literal notranslate"><span class="pre">Resize()</span></code> our images and convert them <code class="docutils literal notranslate"><span class="pre">ToTensor()</span></code></p></li>
<li><p>We use <code class="docutils literal notranslate"><span class="pre">transforms.Compose()</span></code> to chain multiple transformations together:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">TRAIN_DIR</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>

<span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image data type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;     Image size: </span><span class="si">{</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Image data type: &lt;class &#39;torch.Tensor&#39;&gt;
     Image size: torch.Size([3, 64, 64])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Great, but there’s one more issue: we want to work with <strong>batches</strong> of data, because most of the time, we won’t be able to fit an entire dataset into RAM at once (especially when it comes to image data)</p></li>
<li><p>This is where PyTorch’s <code class="docutils literal notranslate"><span class="pre">dataloader</span></code> comes in</p></li>
<li><p>It allows us to specify how we want to batch our data:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">mem</span> <span class="o">=</span> <span class="n">memory_profiler</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>          <span class="c1"># our raw data</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>  <span class="c1"># the size of batches we want the dataloader to return</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>           <span class="c1"># shuffle our data before batching</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span>         <span class="c1"># don&#39;t drop the last batch even if it&#39;s smaller than batch_size</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memory consumed: </span><span class="si">{</span><span class="n">memory_profiler</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mem</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Memory consumed: 0 MB
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Once again, we aren’t loading anything yet, we just prepared the loader</p></li>
</ul>
<p><br><br><br></p>
<ul class="simple">
<li><p>We can now query the loader to return a batch of data (this will consume memory):</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mem</span> <span class="o">=</span> <span class="n">memory_profiler</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">imgs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;       # of batches: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Image data type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Image batch size: </span><span class="si">{</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># dimensions are (batch size, image channels, image height, image width)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Target batch size: </span><span class="si">{</span><span class="n">targets</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;       Batch memory: </span><span class="si">{</span><span class="n">memory_profiler</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mem</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>  <span class="c1"># memory usage after loading batch</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       # of batches: 32
    Image data type: &lt;class &#39;torch.Tensor&#39;&gt;
   Image batch size: torch.Size([64, 3, 64, 64])
  Target batch size: torch.Size([64])
       Batch memory: 7.46 MB
</pre></div>
</div>
</div>
</div>
<p><br><br><br></p>
</section>
<section id="saving-and-loading-pytorch-models">
<h3>1.2 Saving and Loading PyTorch Models<a class="headerlink" href="#saving-and-loading-pytorch-models" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The <a class="reference external" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">PyTorch documentation</a> about saving and loading models is fantastic and the process is very easy</p></li>
<li><p>It’s common PyTorch convention to save models using either a <code class="docutils literal notranslate"><span class="pre">.pt</span></code> or <code class="docutils literal notranslate"><span class="pre">.pth</span></code> file extension</p></li>
<li><p>It is recommended that you just save your model learned parameters from <code class="docutils literal notranslate"><span class="pre">model.state_dict()</span></code>:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save model</span>
<span class="n">PATH</span> <span class="o">=</span> <span class="s2">&quot;models/eva_cnn.pt&quot;</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>     <span class="c1"># save model at PATH</span>

<span class="c1"># Load model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyModelClass</span><span class="p">()</span>                   <span class="c1"># create an instance of the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>  <span class="c1"># load model from PATH</span>
</pre></div>
</div>
<p><br><br><br></p>
<ul class="simple">
<li><p>If you’re using the model for <strong>inference</strong> (not training), make sure to switch it to eval mode: <strong><code class="docutils literal notranslate"><span class="pre">model.eval()</span></code></strong></p></li>
<li><p>There are other options for saving models, in particular, if you want to save a model and continue training it later, you’ll want to save other necessary information like the optimizer state, the epoch you’re on, etc. This is all documented here in the <a class="reference external" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training">PyTorch docs</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Let’s see an example of a model I saved earlier:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">bitmoji_CNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">324</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PATH</span> <span class="o">=</span> <span class="s2">&quot;models/eva_cnn.pt&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bitmoji_CNN</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>bitmoji_CNN(
  (main): Sequential(
    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)
    (6): Dropout(p=0.2, inplace=False)
    (7): Flatten(start_dim=1, end_dim=-1)
    (8): Linear(in_features=324, out_features=128, bias=True)
    (9): ReLU()
    (10): Linear(in_features=128, out_features=1, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Saving the entire model</strong> You can also save the entire model using <code class="docutils literal notranslate"><span class="pre">torch.save(model,</span> <span class="pre">filepath)</span></code>, which serializes the entire model object using Python’s <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module and saves it to a file. It includes not just the model’s <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> but also its class definition and all the hyperparameters.</p></li>
<li><p><strong>Checkpointing during training</strong>: For long-running training, you might want to save more than just the model’s state_dict. Checkpoints typically include the model’s state_dict, the optimizer’s state_dict, and other variables like the current epoch number.</p></li>
</ul>
<p><br><br><br></p>
</section>
<section id="data-augmentation">
<h3>1.3 Data Augmentation<a class="headerlink" href="#data-augmentation" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Data augmentation is used for two main purposes:</p>
<ol class="arabic simple">
<li><p>Make your CNN more robust to certain variations in the dataset (e.g. scaling, rotation)</p></li>
<li><p>Increase the size of your training set</p></li>
</ol>
</li>
</ul>
<p><br><br><br></p>
<ul class="simple">
<li><p>Let’s explore point 1 a bit further. We can see below is a Bitmoji of Eva, does the CNN I loaded above predict this?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;img/test-examples/eva-picnic.png&#39;</span><span class="p">)</span>
<span class="n">image</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/bc0eb9745dde252216671e299c3928d034bd6834ebed3bb50531e0c453123c17.png" src="../_images/bc0eb9745dde252216671e299c3928d034bd6834ebed3bb50531e0c453123c17.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="n">image_tensor</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">classes</span><span class="p">[</span><span class="n">prediction</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Prediction: eva
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>But what happens if I flip my image? Can our CNN still correctly classify the image?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_rotated</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="mi">180</span><span class="p">)</span>
<span class="n">image_rotated</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9ff9376efd45d5347ab416d4beb18acd2ee2501a0fc76ecb7ac177fa6a90b15c.png" src="../_images/9ff9376efd45d5347ab416d4beb18acd2ee2501a0fc76ecb7ac177fa6a90b15c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_tensor</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">image_rotated</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">classes</span><span class="p">[</span><span class="n">prediction</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Prediction: not_eva
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This was just 1 example</p></li>
<li><p>Let’s see what happens if we vertically flip all images in our dataset, and then compute accuracy.</p></li>
<li><p>Here’s a helper function to compute accuracy:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validation wrapper for PyTorch network.&quot;&quot;&quot;</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">y_hat_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_hat_labels</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span>  <span class="c1"># avg accuracy</span>
    
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Now let’s feed the flipped version of the validation set to our model and compute accuracy:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TRAIN_DIR</span> <span class="o">=</span> <span class="s2">&quot;data/eva_bitmoji_rgb/train/&quot;</span>
<span class="n">VALID_DIR</span> <span class="o">=</span> <span class="s2">&quot;data/eva_bitmoji_rgb/valid/&quot;</span>
<span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>


<span class="c1"># Transforms</span>
<span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># flip all images vertically</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>

<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">VALID_DIR</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">)</span>  <span class="c1"># want to test on entire validation set</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.630859375
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The model has basically lost its predication capability, and that’s problematic.</p></li>
</ul>
<p><br><br><br></p>
<ul class="simple">
<li><p>We’d like our CNN to be robust against these kinds of differences</p></li>
<li><p>We can expose our CNN to rotated images, so that it can learn to better predict them, with data augmentation</p></li>
<li><p>Common image augmentations include:</p>
<ul>
<li><p>rotation/flipping</p></li>
<li><p>cropping</p></li>
<li><p>adding noise</p></li>
<li><p>You can view others in the <a class="reference external" href="https://pytorch.org/docs/stable/torchvision/transforms.html">PyTorch docs</a></p></li>
</ul>
</li>
<li><p>We add transforms just like we did previously, using the <code class="docutils literal notranslate"><span class="pre">transform</span></code> argument of <code class="docutils literal notranslate"><span class="pre">torchvision.datasets.ImageFolder()</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>

<span class="n">train_dataset_flipped</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">TRAIN_DIR</span><span class="p">,</span>
                                                 <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>
<span class="n">train_loader_flipped</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset_flipped</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                           <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sample_batch</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader_flipped</span><span class="p">))</span>

<span class="n">valid_dataset_flipped</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">VALID_DIR</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">)</span>  <span class="c1"># want to test on entire validation set</span>
<span class="n">valid_loader_flipped</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plot_bitmojis</span><span class="p">(</span><span class="n">sample_batch</span><span class="p">,</span> <span class="n">rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/bcfb95463ad32b643cd1f46be580edc50592f19d106616fe96a97003983b91f7.png" src="../_images/bcfb95463ad32b643cd1f46be580edc50592f19d106616fe96a97003983b91f7.png" />
</div>
</div>
<ul class="simple">
<li><p>Here’s a model I trained earlier using <strong>augmented</strong> data using the following transformations:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;mps&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="c1"># SOLUTION</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>device(type=&#39;mps&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># PATH = &quot;models/eva_cnn_augmented.pt&quot;</span>
<span class="c1"># torch.save(model_augmented.state_dict(), PATH)     # save model at PATH</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Note that I’ve only used vertical and horizontal flipping of the images, instead of rotating by other angles. In the latter case, I would have had to somehow deal with the empty areas of the rotated images (appearing as black areas around the rotated images above).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PATH</span> <span class="o">=</span> <span class="s2">&quot;models/eva_cnn_augmented.pt&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bitmoji_CNN</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Let’s try it out on the flipped image:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_rotated</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9ff9376efd45d5347ab416d4beb18acd2ee2501a0fc76ecb7ac177fa6a90b15c.png" src="../_images/9ff9376efd45d5347ab416d4beb18acd2ee2501a0fc76ecb7ac177fa6a90b15c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_tensor</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">image_rotated</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">classes</span><span class="p">[</span><span class="n">prediction</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Prediction: eva
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Looking good. Let’s once again compute accuracy for the flipped version of the validation set:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.880859375
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This time, the CNN trained with augmented dataset demonstrates similar performance on the rotated version of the bitmojis.</p></li>
</ul>
<p><br><br><br></p>
</section>
<section id="optional-batch-normalization">
<h3>1.4 (Optional) Batch Normalization<a class="headerlink" href="#optional-batch-normalization" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Earlier in the course, we saw how normalizing the inputs to our neural network can help our optimization (by making sure the scale of one feature doesn’t overwhelm others)</p></li>
<li><p>But what about the hidden layers of our network? They also have data flowing into them and parameters to optimize, can we normalize them too to make optimization better?</p></li>
<li><p>Batch normalization is the normalization of data in hidden layers</p></li>
<li><p>It is usually applied before (and sometimes after) the activation function of a hidden layer:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[z^* = \frac{z - \mu}{\sqrt{\sigma^2 + \eta}}\times \gamma + \beta\]</div>
<ul class="simple">
<li><p>Where:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(z\)</span> = the output of your hidden layers before/after the activation function</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu = \frac{1}{n}\sum_{i=1}^{n}z_i\)</span> (i.e., the mean of <span class="math notranslate nohighlight">\(z\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^2 = \frac{1}{n}\sum_{i=1}^{n}(z_i-\mu)^2\)</span> (i.e, the variance of <span class="math notranslate nohighlight">\(z\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> are parameters that are learned through backpropagation</p></li>
</ul>
</li>
<li><p>Batch normalization can help stabilize and speed up optimization, make your network more invariant to changes in the training distribution, and often has a slight regularization effect</p></li>
<li><p>Even though we have some guiding intuitions about the mechanics of batch normalization, we still don’t have a widely accepted theory for how <em>exactly</em> this technique works the way it does</p>
<ul>
<li><p>“<em>Somewhat shockingly, however, despite its prominence, we still have a poor understanding of what the effectiveness of BatchNorm is stemming from.</em>” (<a class="reference external" href="https://arxiv.org/abs/1805.11604">Santurkar et al., 2018</a>)</p></li>
<li><p>Read more about this issue <a class="reference external" href="https://www.d2l.ai/chapter_convolutional-modern/batch-norm.html#discussion">here</a></p></li>
</ul>
</li>
</ul>
<p><br><br><br></p>
</section>
</section>
<section id="hyperparameter-tuning">
<h2>2. Hyperparameter Tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>With neural networks we potentially have a lot of hyperparameters to tune:</p>
<ul>
<li><p>Number of layers</p></li>
<li><p>Number of nodes in each layer</p></li>
<li><p>Activation functions</p></li>
<li><p>Regularization</p></li>
<li><p>Initialization (starting weights)</p></li>
<li><p>Optimization hyperparameters (learning rate, momentum, weight decay)</p></li>
<li><p>etc.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>When the number of hyperparameters are large and models are expensive to compute, brute force strategies such as <strong>grid search</strong> perform poorly. In these cases, we need to make our approach smarter. For example, we can use an optimization algorithm instead of blindly evaluating our model for all values of hyperparameters.</p></li>
<li><p>There are many packages out there that make neural network hyperparameter tuning fast and easy using such approaches</p>
<ul>
<li><p><a class="reference external" href="https://ax.dev/">Ax</a></p></li>
<li><p><a class="reference external" href="https://docs.ray.io/en/latest/tune/index.html">Raytune</a></p></li>
<li><p><a class="reference external" href="https://neptune.ai/">Neptune</a></p></li>
<li><p><a class="reference external" href="https://skorch.readthedocs.io/en/stable/index.html">skorch</a></p></li>
</ul>
</li>
<li><p>We’ll be using <a class="reference external" href="https://ax.dev/">Ax</a>, created by Facebook (just like PyTorch)</p></li>
<li><p>Ax uses Bayesian optimization to tune the hyperparameters of our model (how? see <a class="reference external" href="https://ax.dev/docs/bayesopt.html#how-does-it-work">here</a>)</p></li>
</ul>
<p><br><br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !conda install -y ax-platform</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Below, I’ve adapted a tutorial from <a class="reference external" href="https://ax.dev/tutorials/tune_cnn.html">their docs</a>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ax.service.managed_loop</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">from</span> <span class="nn">ax.plot.contour</span> <span class="kn">import</span> <span class="n">plot_contour</span>
<span class="kn">from</span> <span class="nn">ax.plot.trace</span> <span class="kn">import</span> <span class="n">optimization_trace_single_method</span>
<span class="kn">from</span> <span class="nn">ax.utils.notebook.plotting</span> <span class="kn">import</span> <span class="n">render</span><span class="p">,</span> <span class="n">init_notebook_plotting</span>
<span class="kn">from</span> <span class="nn">ax.utils.tutorials.cnn_utils</span> <span class="kn">import</span> <span class="n">train</span><span class="p">,</span> <span class="n">evaluate</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>First, I’ll create some simple training and validation loaders:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TRAIN_DIR</span> <span class="o">=</span> <span class="s2">&quot;data/eva_bitmoji_rgb/train/&quot;</span>
<span class="n">VALID_DIR</span> <span class="o">=</span> <span class="s2">&quot;data/eva_bitmoji_rgb/valid/&quot;</span>
<span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># Transforms</span>
<span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>

<span class="c1"># Load data and create dataloaders</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">TRAIN_DIR</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">VALID_DIR</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># GPU available?</span>
<span class="c1"># device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;mps&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bitmoji_CNN</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using: mps
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Now, we need a training function</p></li>
<li><p>This function will be re-run multiple times throughout the hyperparameter optimization process, as we wish to train the model on different hyperparameter configurations</p></li>
<li><p>The argument <code class="docutils literal notranslate"><span class="pre">hyperparameters</span></code> is a dictionary containing the hyperparameters we wish to tune:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">hyperparameters</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Training wrapper for PyTorch network.&quot;&quot;&quot;</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                           <span class="n">lr</span><span class="o">=</span><span class="n">hyperparameters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">),</span>
                           <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">hyperparameters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;beta1&quot;</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">),</span> <span class="mf">0.999</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="s1">&#39;mps&#39;</span><span class="p">]:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We also need an <code class="docutils literal notranslate"><span class="pre">evaluate()</span></code> function that reports how well our model is doing on some validation data</p></li>
<li><p>This will also be called multiple times during the hyperparameter optimization</p></li>
<li><p>We have already defined such a function before in this lecture, but here is its definition again:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validation wrapper for PyTorch network.&quot;&quot;&quot;</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># this stops pytorch doing computational graph stuff under-the-hood and saves memory and time</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="s1">&#39;mps&#39;</span><span class="p">]:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">y_hat_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_hat_labels</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span>  <span class="c1"># avg accuracy</span>
    
    <span class="k">return</span> <span class="n">accuracy</span>    
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Let’s make sure our evaluation function is working:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.47265625
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The accuracy is bad right now because we haven’t trained our model yet</p></li>
<li><p>We then have a wrapper function that puts everything together</p></li>
<li><p>Basically each iteration of hyperparameter optimization (i.e., each time we try a new set of hyperparameters), this function is executed. It trains the model using the given hyperparameters, and then evaluates the model’s performance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_evaluate</span><span class="p">(</span><span class="n">parameterization</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">bitmoji_CNN</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">hyperparameters</span><span class="o">=</span><span class="n">parameterization</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Finally, we use <code class="docutils literal notranslate"><span class="pre">optimize()</span></code> to run Bayesian optimization on a hyperparameter dictionary</p></li>
<li><p>I ran this on a GPU and have included the output below:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_parameters</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">experiment</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span>
    <span class="n">parameters</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;range&quot;</span><span class="p">,</span> <span class="s2">&quot;bounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="s2">&quot;log_scale&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;value_type&quot;</span><span class="p">:</span> <span class="s1">&#39;float&#39;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;beta1&quot;</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;range&quot;</span><span class="p">,</span> <span class="s2">&quot;bounds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">],</span> <span class="s2">&quot;value_type&quot;</span><span class="p">:</span> <span class="s1">&#39;float&#39;</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">evaluation_function</span><span class="o">=</span><span class="n">train_evaluate</span><span class="p">,</span>
    <span class="n">objective_name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>
    <span class="n">total_trials</span> <span class="o">=</span> <span class="mi">20</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">25</span><span class="p">:</span><span class="mi">27</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">modelbridge</span><span class="o">.</span><span class="n">dispatch_utils</span><span class="p">:</span> <span class="n">Using</span> <span class="n">Bayesian</span> <span class="n">Optimization</span> <span class="n">generation</span> <span class="n">strategy</span><span class="p">:</span> <span class="n">GenerationStrategy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Sobol+GPEI&#39;</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="p">[</span><span class="n">Sobol</span> <span class="k">for</span> <span class="mi">5</span> <span class="n">trials</span><span class="p">,</span> <span class="n">GPEI</span> <span class="k">for</span> <span class="n">subsequent</span> <span class="n">trials</span><span class="p">])</span><span class="o">.</span> <span class="n">Iterations</span> <span class="n">after</span> <span class="mi">5</span> <span class="n">will</span> <span class="n">take</span> <span class="n">longer</span> <span class="n">to</span> <span class="n">generate</span> <span class="n">due</span> <span class="n">to</span>  <span class="n">model</span><span class="o">-</span><span class="n">fitting</span><span class="o">.</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">25</span><span class="p">:</span><span class="mi">27</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Started</span> <span class="n">full</span> <span class="n">optimization</span> <span class="k">with</span> <span class="mi">20</span> <span class="n">steps</span><span class="o">.</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">25</span><span class="p">:</span><span class="mi">27</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">1.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">26</span><span class="p">:</span><span class="mi">28</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">2.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">27</span><span class="p">:</span><span class="mi">25</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">3.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">28</span><span class="p">:</span><span class="mi">20</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">4.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">29</span><span class="p">:</span><span class="mi">13</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">5.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">30</span><span class="p">:</span><span class="mi">06</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">6.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mi">01</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">7.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mi">57</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">8.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">32</span><span class="p">:</span><span class="mi">52</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">9.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">33</span><span class="p">:</span><span class="mi">46</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">10.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">34</span><span class="p">:</span><span class="mi">41</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">11.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">35</span><span class="p">:</span><span class="mi">36</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">12.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">13.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">37</span><span class="p">:</span><span class="mi">25</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">14.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">38</span><span class="p">:</span><span class="mi">20</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">15.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">39</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">16.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">40</span><span class="p">:</span><span class="mi">08</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">17.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">41</span><span class="p">:</span><span class="mi">03</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">18.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">41</span><span class="p">:</span><span class="mi">59</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">19.</span><span class="o">..</span>
<span class="p">[</span><span class="n">INFO</span> <span class="mi">01</span><span class="o">-</span><span class="mi">28</span> <span class="mi">17</span><span class="p">:</span><span class="mi">43</span><span class="p">:</span><span class="mi">01</span><span class="p">]</span> <span class="n">ax</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">managed_loop</span><span class="p">:</span> <span class="n">Running</span> <span class="n">optimization</span> <span class="n">trial</span> <span class="mf">20.</span><span class="o">..</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_parameters</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.0015762617170424081</span><span class="p">,</span> <span class="s1">&#39;beta1&#39;</span><span class="p">:</span> <span class="mf">0.6464455205729447</span><span class="p">}</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">means</span><span class="p">,</span> <span class="n">covariances</span> <span class="o">=</span> <span class="n">values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">means</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">:</span> <span class="mf">86.91</span><span class="o">%</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">render</span><span class="p">(</span><span class="n">plot_contour</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_x</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">param_y</span><span class="o">=</span><span class="s1">&#39;beta1&#39;</span><span class="p">,</span> <span class="n">metric_name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<a class="reference internal image-reference" href="../_images/hyperparam-tuning.png"><img alt="../_images/hyperparam-tuning.png" src="../_images/hyperparam-tuning.png" style="width: 800px;" /></a>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_objectives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span><span class="n">trial</span><span class="o">.</span><span class="n">objective_mean</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="n">experiment</span><span class="o">.</span><span class="n">trials</span><span class="o">.</span><span class="n">values</span><span class="p">()]]</span>
<span class="p">)</span>
<span class="n">best_objective_plot</span> <span class="o">=</span> <span class="n">optimization_trace_single_method</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">best_objectives</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Model performance vs. # of iterations&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Classification Accuracy, %&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">render</span><span class="p">(</span><span class="n">best_objective_plot</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<a class="reference internal image-reference" href="../_images/hyperparam-tuning-2.png"><img alt="../_images/hyperparam-tuning-2.png" src="../_images/hyperparam-tuning-2.png" style="width: 600px;" /></a>
<p><br><br><br></p>
</section>
<section id="optional-explaining-cnns">
<h2>3. (Optional) Explaining CNNs<a class="headerlink" href="#optional-explaining-cnns" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>CNNs and neural networks in general are primarily used for <strong>prediction</strong> (i.e., we want the best prediction performance, and we might not care how we get it)</p></li>
<li><p>However interpreting why a model makes certain predictions can be useful</p></li>
<li><p>Interpreting neural networks is an active area of research and it is difficult to do</p></li>
<li><p>There are a few main options:</p>
<ul>
<li><p><a class="reference external" href="https://shap.readthedocs.io/en/latest/image_examples.html">SHAP</a></p></li>
<li><p><a class="reference external" href="https://github.com/jacobgil/pytorch-grad-cam">Grad-CAM</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/captum">Captum</a></p></li>
</ul>
</li>
<li><p>Captum is a library for specifically interpreting PyTorch models. It’s quite new still but has some great functionality!</p></li>
<li><p>Captum contains a variety of state-of-the-art algorithms for interpreting model predictions, see the <a class="reference external" href="https://captum.ai/docs/attribution_algorithms">docs here</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !conda install -y captum</span>
</pre></div>
</div>
</div>
</div>
<p><br><br><br></p>
</section>
<section id="transfer-learning">
<h2>4. Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>In practice, very few people train an entire CNN from scratch because it requires a large dataset, powerful computers, and a huge amount of human effort to train the model.</p></li>
<li><p>Instead, a common practice is to download a pre-trained model and fine tune it for your task. This is called <strong>transfer learning</strong>.</p></li>
<li><p>Transfer learning is one of the most common techniques used in the context of computer vision and natural language processing.</p></li>
<li><p>It refers to using a model already trained on one task as a starting point for learning to perform another task</p></li>
<li><p>There are many famous deep learning architectures out there that have been very successful across a wide range of problems, e.g.: <a class="reference external" href="https://arxiv.org/abs/1404.5997">AlexNet</a>, <a class="reference external" href="https://arxiv.org/abs/1409.1556">VGG</a>, <a class="reference external" href="https://arxiv.org/abs/1512.03385">ResNet</a>, <a class="reference external" href="https://arxiv.org/abs/1512.00567">Inception</a>, <a class="reference external" href="https://arxiv.org/abs/1801.04381">MobileNet</a>, etc.</p></li>
<li><p>Many of these models have been pre-trained on famous datasets like ImageNet [<a class="reference external" href="https://www.image-net.org/index.php">1</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/ImageNet">2</a>]</p></li>
</ul>
<p><strong><a class="reference external" href="https://www.image-net.org/about.php">ImageNet</a></strong></p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.image-net.org/">ImageNet</a> is an image dataset that became a very popular benchmark in the field ~10 years ago.</p></li>
<li><p>Currently contains ~14 million labelled images with ~21,841 categories</p></li>
<li><p>There are various versions with different number of images and classes</p>
<ul>
<li><p>ILSVRC, a popular annual competition in computer vision, uses a smaller subset of ImageNet. This subset consists of about 1.2 million training images, 50,000 validation images, and 150,000 testing images across 1,000 categories.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/ImageNet">Wikipedia article</a> on ImageNet</p></li>
<li><p>Here are some example classes.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/imagenet_classes.txt&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
<span class="n">classes</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;black swan, Cygnus atratus&#39;,
 &#39;tusker&#39;,
 &#39;echidna, spiny anteater, anteater&#39;,
 &#39;platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus&#39;,
 &#39;wallaby, brush kangaroo&#39;,
 &#39;koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus&#39;,
 &#39;wombat&#39;,
 &#39;jellyfish&#39;,
 &#39;sea anemone, anemone&#39;,
 &#39;brain coral&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The idea of transfer learning is instead of developing a machine learning model from scratch, you use these available pre-trained models for your tasks either directly or by fine tuning them.</p></li>
<li><p>There are three common ways to use transfer learning in computer vision</p>
<ol class="arabic simple">
<li><p>Using pre-trained models out-of-the-box</p></li>
<li><p>Using pre-trained models as feature extractor and training your own model with these features</p></li>
<li><p>Starting with weights of pre-trained models and fine-tuning the weights for your task.</p></li>
</ol>
</li>
<li><p>We will explore the first two approaches.</p></li>
</ul>
<p><br><br></p>
<section id="using-pre-trained-models-out-of-the-box">
<h3>4.1 Using pre-trained models out-of-the-box<a class="headerlink" href="#using-pre-trained-models-out-of-the-box" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Let’s first try one of these models and apply it to our own problem right out of the box</p></li>
</ul>
<p><img alt="" src="../_images/cnn-ex.png" /></p>
<p>Source: https://cezannec.github.io/Convolutional_Neural_Networks/</p>
<ul class="simple">
<li><p>We can easily download famous models using the <code class="docutils literal notranslate"><span class="pre">torchvision.models</span></code> module. All models are available with pre-trained weights (based on ImageNet’s 224 x 224 images)</p></li>
<li><p>Remember this example I showed you in the intro video of DSCI 571?</p>
<ul>
<li><p>We used a pre-trained model vgg16 which is trained on the ImageNet data.</p></li>
<li><p>We preprocess the given image.</p></li>
<li><p>We get prediction from this pre-trained model on a given image along with prediction probabilities.</p></li>
<li><p>For a given image, this model will spit out one of the 1000 classes from ImageNet.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">classify_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">topn</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">vgg16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;VGG16_Weights.DEFAULT&#39;</span><span class="p">)</span> <span class="c1"># initialize the classifier with VGG16 weights</span>
    <span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                 <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">299</span><span class="p">),</span>
                 <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">299</span><span class="p">),</span>
                 <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                 <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> 
                                     <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),])</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/imagenet_classes.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
    
    <span class="n">img_t</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">batch_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">img_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">clf</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Class&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">classes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="n">topn</span><span class="p">]],</span> 
         <span class="s1">&#39;Probability score&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="n">topn</span><span class="p">]]}</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="s1">&#39;Probability score&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">vgg16</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict labels with associated probabilities for unseen images</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;img/test_img/*.*&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">img</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">classify_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------------------------------------------------------&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/a9c35598e692264484006d6e57cd5b82d16999c019fb364db632ceb93fcf32a0.png" src="../_images/a9c35598e692264484006d6e57cd5b82d16999c019fb364db632ceb93fcf32a0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                     Class  Probability score
         cheetah, chetah, Acinonyx jubatus              0.983
                  leopard, Panthera pardus              0.012
jaguar, panther, Panthera onca, Felis onca              0.004
       snow leopard, ounce, Panthera uncia              0.001
--------------------------------------------------------------
</pre></div>
</div>
<img alt="../_images/aad340e10e00ac42397f2461a725caba30ed1ce75c9ce3bfbbb3eec9b1decd7d.png" src="../_images/aad340e10e00ac42397f2461a725caba30ed1ce75c9ce3bfbbb3eec9b1decd7d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                         Class  Probability score
                     tiger cat              0.353
              tabby, tabby cat              0.207
               lynx, catamount              0.050
Pembroke, Pembroke Welsh corgi              0.046
--------------------------------------------------------------
</pre></div>
</div>
<img alt="../_images/81889c636d7377036e53dbe5af75dde8492b9668623e8a460fa45bb8013c997b.png" src="../_images/81889c636d7377036e53dbe5af75dde8492b9668623e8a460fa45bb8013c997b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                   Class  Probability score
                                 macaque              0.714
patas, hussar monkey, Erythrocebus patas              0.122
      proboscis monkey, Nasalis larvatus              0.098
                   guenon, guenon monkey              0.017
--------------------------------------------------------------
</pre></div>
</div>
<img alt="../_images/e3512ea425eecded6b102a140a25af24d29c5c74ac01329d894b1f9038db6449.png" src="../_images/e3512ea425eecded6b102a140a25af24d29c5c74ac01329d894b1f9038db6449.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                        Class  Probability score
Walker hound, Walker foxhound              0.580
             English foxhound              0.091
                  EntleBucher              0.080
                       beagle              0.065
--------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We got these predictions without “doing the ML ourselves”.</p></li>
<li><p>We are using <strong>pre-trained</strong> <code class="docutils literal notranslate"><span class="pre">vgg16</span></code> model which is available in <code class="docutils literal notranslate"><span class="pre">torchvision</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torchvision</span></code> has many such pre-trained models available that have been very successful across a wide range of tasks: AlexNet, VGG, ResNet, Inception, MobileNet, etc.</p></li>
<li><p>Many of these models have been pre-trained on famous datasets like <strong>ImageNet</strong>.</p></li>
<li><p>So if we use them out-of-the-box, they will give us one of the ImageNet classes as classification.</p></li>
</ul>
<p>Let’s try it out on some very different from the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict labels with associated probabilities for unseen images</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;img/UBC_img/*.*&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">img</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">classify_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------------------------------------------------------&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5dfd5e34aceac6f010bc574c140a02241ccacd83c3204c854b24c55f75864f81.png" src="../_images/5dfd5e34aceac6f010bc574c140a02241ccacd83c3204c854b24c55f75864f81.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                      Class  Probability score
                                        fig              0.637
                                pomegranate              0.193
grocery store, grocery, food market, market              0.041
                                      crate              0.023
--------------------------------------------------------------
</pre></div>
</div>
<img alt="../_images/c1a4d280efed3440266dac6e844e1c3e0fe6fcba5ffc9a257e59a93bd4f75a56.png" src="../_images/c1a4d280efed3440266dac6e844e1c3e0fe6fcba5ffc9a257e59a93bd4f75a56.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                               Class  Probability score
                                         toilet seat              0.171
                                          safety pin              0.060
bannister, banister, balustrade, balusters, handrail              0.039
                                              bubble              0.035
--------------------------------------------------------------
</pre></div>
</div>
<img alt="../_images/80a233c015055253fcffe5e714cdfb0a83753a74ef1bfb3c0bc76b074d23cadf.png" src="../_images/80a233c015055253fcffe5e714cdfb0a83753a74ef1bfb3c0bc76b074d23cadf.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                    Class  Probability score
worm fence, snake fence, snake-rail fence, Virginia fence              0.202
                                                     barn              0.036
                                                   sorrel              0.033
                                             valley, vale              0.029
--------------------------------------------------------------
</pre></div>
</div>
<img alt="../_images/cd5c72cf78394728eff64aba299811a544405698ad1ca6fa716bd3202802bfb4.png" src="../_images/cd5c72cf78394728eff64aba299811a544405698ad1ca6fa716bd3202802bfb4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              Class  Probability score
     patio, terrace              0.213
           fountain              0.164
lakeside, lakeshore              0.097
            sundial              0.088
--------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>It’s not doing very well here because ImageNet don’t have proper classes for these images.</p></li>
<li><p>Here we are using pre-trained models out-of-the-box.</p></li>
<li><p>Can we use pre-trained models for our own classification problem with our classes?</p></li>
<li><p>Yes!! There are two ways to benefit from transfer learning:</p>
<ol class="arabic simple">
<li><p>Use a pre-trained network as a “<strong>feature extractor</strong>” and add new layers to it for your own task</p></li>
<li><p>Same as the previous one, but also “<strong>fine-tune</strong>” the weights of the pre-trained network using your own data</p></li>
</ol>
</li>
</ul>
<p><br><br><br></p>
</section>
<section id="using-pre-trained-models-as-feature-extractors">
<h3>4.2 Using pre-trained models as feature extractors<a class="headerlink" href="#using-pre-trained-models-as-feature-extractors" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>In this method, we use a pre-trained model as a “feature extractor” which creates useful features for us that we can use to train some other model</p></li>
<li><p>We have two options here:</p>
<ol class="arabic simple">
<li><p>Add some extra layers to the pre-trained network to suit our particular task</p></li>
<li><p>Pass training data through the network and save the output to use as features for training some other model</p></li>
</ol>
</li>
</ul>
<p><br><br><br></p>
</section>
<section id="approach-1-adding-extra-layers-to-the-pre-trained-network">
<h3>4.2.1 Approach 1: Adding extra layers to the pre-trained network<a class="headerlink" href="#approach-1-adding-extra-layers-to-the-pre-trained-network" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Let’s do approach 1 first. Let’s adapt <code class="docutils literal notranslate"><span class="pre">DenseNet</span></code> to predict our bitmoji data. I’m going to load the model, and then “freeze” all of its parameters (we don’t want to update them)</p></li>
</ul>
<p><strong>(Optional)</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">DenseNet paper</a></p></li>
<li><p>This architecture connects each layer to every other layer in a feed-forward fashion.</p></li>
<li><p>The dense connectivity ensures maximum information flow between layers in the network. This connectivity leads to significant improvements in efficiency and effectiveness in learning, as each layer has access to all preceding layers’ feature maps.
<img alt="" src="../_images/densenet.png" /></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">densenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">densenet121</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;DenseNet121_Weights.DEFAULT&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">densenet</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>  <span class="c1"># Freeze parameters so we don&#39;t update them</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The layers can be accessed using the <code class="docutils literal notranslate"><span class="pre">.named_children()</span></code> method, the last one is the classification layer, a fully-connected layer outputting 1000 values (one for each ImageNet class):</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">densenet</span><span class="o">.</span><span class="n">named_children</span><span class="p">())[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;classifier&#39;, Linear(in_features=1024, out_features=1000, bias=True))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">densenet</span><span class="o">.</span><span class="n">classifier</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linear(in_features=1024, out_features=1000, bias=True)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We are going to do binary classification, so let’s replace this layer with our own layers:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">densenet</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">new_layers</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Let’s check that the last layer of our model is updated:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">densenet</span><span class="o">.</span><span class="n">classifier</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sequential(
  (0): Linear(in_features=1024, out_features=500, bias=True)
  (1): ReLU()
  (2): Linear(in_features=500, out_features=1, bias=True)
)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Now we need to train our new layers:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># New dataloaders</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">TRAIN_DIR</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">VALID_DIR</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">data_transforms</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simple training wrapper for PyTorch network.&quot;&quot;&quot;</span>
    
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">valid_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>  <span class="c1"># for each epoch</span>
        <span class="n">train_batch_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">train_batch_acc</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">valid_batch_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">valid_batch_acc</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># Training</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="s1">&#39;mps&#39;</span><span class="p">]:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">y_hat_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">train_batch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">train_batch_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_hat_labels</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">train_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_batch_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
        
        <span class="c1"># Validation</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="s1">&#39;mps&#39;</span><span class="p">]:</span>
                    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="n">y_hat_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
                <span class="n">valid_batch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">valid_batch_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_hat_labels</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">valid_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_batch_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="c1"># Print progress</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">,</span>
                  <span class="sa">f</span><span class="s2">&quot;Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                  <span class="sa">f</span><span class="s2">&quot;Valid Accuracy: </span><span class="si">{</span><span class="n">valid_accuracy</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;train_accuracy&quot;</span><span class="p">:</span> <span class="n">train_accuracy</span><span class="p">,</span> <span class="s2">&quot;valid_accuracy&quot;</span><span class="p">:</span> <span class="n">valid_accuracy</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We have a big model so this will take some time to run! If you have a GPU, things could be much faster!</span>
<span class="n">densenet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">densenet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">(</span><span class="n">densenet</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: Train Accuracy: 0.59 Valid Accuracy: 0.66
Epoch 2: Train Accuracy: 0.73 Valid Accuracy: 0.70
Epoch 3: Train Accuracy: 0.76 Valid Accuracy: 0.71
Epoch 4: Train Accuracy: 0.80 Valid Accuracy: 0.71
Epoch 5: Train Accuracy: 0.82 Valid Accuracy: 0.74
Epoch 6: Train Accuracy: 0.83 Valid Accuracy: 0.75
Epoch 7: Train Accuracy: 0.84 Valid Accuracy: 0.76
Epoch 8: Train Accuracy: 0.87 Valid Accuracy: 0.76
Epoch 9: Train Accuracy: 0.87 Valid Accuracy: 0.74
Epoch 10: Train Accuracy: 0.88 Valid Accuracy: 0.78
</pre></div>
</div>
</div>
</div>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.68</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.72</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.77</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.71</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">3</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.80</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.73</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">4</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.86</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.78</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">5</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.89</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.81</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">6</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.90</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.81</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">7</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.90</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.80</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">8</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.94</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.84</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">9</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.95</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.85</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">10</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.96</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.84</span>
</pre></div>
</div>
<ul class="simple">
<li><p>We leveraged the power of <code class="docutils literal notranslate"><span class="pre">DenseNet</span></code> to get a good model, <strong>without training any convolutional layers ourselves</strong>.</p></li>
</ul>
<p><br><br><br></p>
</section>
<section id="approach-2-using-extracted-features-in-other-models">
<h3>4.2.2 Approach 2: Using extracted features in other models<a class="headerlink" href="#approach-2-using-extracted-features-in-other-models" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Now, you can use pre-trained model as arbitrary feature extractors, you don’t have to add on layers, you can just extract the output values of the network (well, you can extract values from any layer you like) and use those values as “features” to train another model</p></li>
<li><p>Below, I’m going to pass all my bitmoji data through the network and save the outputs:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_features</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract features from both training and validation datasets using the provided model.</span>

<span class="sd">    This function passes data through a given neural network model to extract features. It&#39;s designed </span>
<span class="sd">    to work with datasets loaded using PyTorch&#39;s DataLoader. The function operates under the assumption </span>
<span class="sd">    that gradients are not required, optimizing memory and computation for inference tasks.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Disable gradient computation for efficiency during inference</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># Initialize empty tensors for training features and labels</span>
        <span class="n">Z_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1024</span><span class="p">))</span>  <span class="c1"># Assuming each feature vector has 1024 elements</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># Initialize empty tensors for validation features and labels</span>
        <span class="n">Z_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1024</span><span class="p">))</span>
        <span class="n">y_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># Process training data</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="c1"># Extract features and concatenate them to the corresponding tensors</span>
            <span class="n">Z_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">Z_train</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

        <span class="c1"># Process validation data</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="c1"># Extract features and concatenate them to the corresponding tensors</span>
            <span class="n">Z_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">Z_valid</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">y_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="c1"># Return the feature and label tensors</span>
    <span class="k">return</span> <span class="n">Z_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">Z_valid</span><span class="p">,</span> <span class="n">y_valid</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">densenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">densenet121</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;DenseNet121_Weights.DEFAULT&#39;</span><span class="p">)</span>
<span class="n">densenet</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>  <span class="c1"># remove that last &quot;classification&quot; layer</span>
<span class="n">Z_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">Z_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">get_features</span><span class="p">(</span><span class="n">densenet</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2038, 1024])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Now we have some extracted features</p></li>
<li><p>Let’s train a classifier on the data, say, a <code class="docutils literal notranslate"><span class="pre">LogisticRegression()</span></code> model:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s scale our data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">Z_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Z_train</span><span class="p">)</span>
<span class="n">Z_valid</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Z_valid</span><span class="p">)</span>

<span class="c1"># Fit a model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Z_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Valid accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Z_valid</span><span class="p">,</span><span class="w"> </span><span class="n">y_valid</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train accuracy: 100.00%
Valid accuracy: 79.49%
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>So what did we just do:</p>
<ol class="arabic simple">
<li><p>We passed out bitmoji images through DenseNet and saved all the output values. DenseNet outputs 1024 values per input. We had 2038 bitmoji images, so we extracted a tensor of shape <code class="docutils literal notranslate"><span class="pre">(2038,</span> <span class="pre">1024)</span></code> from DenseNet.</p></li>
<li><p>We now have a dataset of 1024 features and 2038 examples for a binary classification problem</p></li>
<li><p>We used this data to train a logistic regression model.</p></li>
</ol>
</li>
</ul>
<p><br><br><br></p>
</section>
<section id="using-pre-trained-models-for-fine-tuning">
<h3>4.3 Using pre-trained models for fine tuning<a class="headerlink" href="#using-pre-trained-models-for-fine-tuning" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Alright, this is the final and most common workflow of transfer learning</p></li>
<li><p>Above, we stacked some extra layers onto <code class="docutils literal notranslate"><span class="pre">DenseNet</span></code> and just trained those layer (we “froze” all of <code class="docutils literal notranslate"><span class="pre">DenseNet</span></code>’s weights)</p></li>
<li><p>But we can also “fine tune” <code class="docutils literal notranslate"><span class="pre">DenseNet</span></code>’s weights if we like, to make it more suited to our data</p></li>
<li><p>We can choose to “fine tune” all of <code class="docutils literal notranslate"><span class="pre">DenseNet</span></code>’s ~8 million parameters, or just some of them</p></li>
<li><p>To do this, we use the same workflow as above, but we unfreeze the layers we wish to “fine-tune”</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load (but don&#39;t freeze) the model</span>
<span class="n">densenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">densenet121</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;DenseNet121_Weights.DEFAULT&#39;</span><span class="p">)</span>

<span class="c1"># Replace classification layer</span>
<span class="n">new_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">densenet</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">new_layers</span>

<span class="c1"># Move to GPU if available</span>
<span class="c1"># device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;mps&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">densenet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">densenet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">(</span><span class="n">densenet</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: Train Accuracy: 0.82 Valid Accuracy: 0.83
Epoch 2: Train Accuracy: 0.93 Valid Accuracy: 0.84
Epoch 3: Train Accuracy: 0.96 Valid Accuracy: 0.95
</pre></div>
</div>
</div>
</div>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.79</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.61</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.95</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.97</span>
<span class="n">Epoch</span><span class="w"> </span><span class="mi">3</span><span class="o">:</span><span class="w"> </span><span class="n">Train</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.98</span><span class="w"> </span><span class="n">Valid</span><span class="w"> </span><span class="n">Accuracy</span><span class="o">:</span><span class="w"> </span><span class="mf">0.98</span>
</pre></div>
</div>
<ul class="simple">
<li><p>By far our best results yet</p></li>
<li><p>You could also choose to fine-tune just some layers. For example, below I’ll freeze everything but the last two layers:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Freeze all but the last two layers</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">densenet</span><span class="o">.</span><span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        
<span class="c1"># Now re-train...</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Fine-tuning more layers typically leads to better accuracy, but we have to pay the cost of training.</p></li>
</ul>
<p><br><br><br></p>
</section>
<section id="transfer-learning-summary">
<h3>4.4 Transfer Learning Summary<a class="headerlink" href="#transfer-learning-summary" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Use a pre-trained model as a “feature extractor” (good if you want to adapt a pre-trained model for a specific problem)</p></li>
<li><p>Fine-tune a pre-trained model (same as 2 but generally yields better results, although at more computational cost)</p></li>
</ol>
<p><br><br><br></p>
</section>
</section>
<section id="lecture-highlights">
<h2>5. Lecture Highlights<a class="headerlink" href="#lecture-highlights" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>PyTorch makes data loading easy with <code class="docutils literal notranslate"><span class="pre">dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">dataloader</span></code>.</p></li>
<li><p>Hyperparameter tuning is hard. Don’t do grid-search when the cost of computations is very high. Use smarter methods such as <a class="reference external" href="https://ax.dev/">Ax</a>.</p></li>
<li><p>Transfer learning is a very powerful method to adapt successful models and datasets to your own problem.</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "dsci572"
        },
        kernelOptions: {
            name: "dsci572",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'dsci572'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="06_cnns-pt1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 6: Introduction to Convolutional Neural Networks</p>
      </div>
    </a>
    <a class="right-next"
       href="08_advanced-deep-learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 8: Advanced Convolutional Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-learning-objectives">Lecture Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap">Recap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datasets-dataloaders-and-transforms">1. Datasets, Dataloaders, and Transforms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-data">1.1 Preparing Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading-pytorch-models">1.2 Saving and Loading PyTorch Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation">1.3 Data Augmentation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-batch-normalization">1.4 (Optional) Batch Normalization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">2. Hyperparameter Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-explaining-cnns">3. (Optional) Explaining CNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">4. Transfer Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pre-trained-models-out-of-the-box">4.1 Using pre-trained models out-of-the-box</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pre-trained-models-as-feature-extractors">4.2 Using pre-trained models as feature extractors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-adding-extra-layers-to-the-pre-trained-network">4.2.1 Approach 1: Adding extra layers to the pre-trained network</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-using-extracted-features-in-other-models">4.2.2 Approach 2: Using extracted features in other models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pre-trained-models-for-fine-tuning">4.3 Using pre-trained models for fine tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning-summary">4.4 Transfer Learning Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-highlights">5. Lecture Highlights</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varada Kolhatkar
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>