{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 572 Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "You'll first need to install TensorFlow, which should be possible with\n",
    "\n",
    "```\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "Note that we will be using TensorFlow 2. If you had TensorFlow 1 installed previously, you may need to remove it or upgrade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ # should print 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow.keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={mechanics:10}\n",
    "\n",
    "Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0: neural networks \"by hand\"\n",
    "\n",
    "#### 0(a)\n",
    "rubric={reasoning:10}\n",
    "\n",
    "Suppose that we use a neural network with one hidden layer and ReLU activations for a regression problem. After training, we obtain the following parameters:\n",
    "\n",
    "$$\\begin{align}W^{(0)} &= \\begin{bmatrix}-2 & 2 & -1\\\\-1 & -2 & 0\\end{bmatrix},  &b^{(0)}&=\\begin{bmatrix}2 \\\\ 0\\end{bmatrix} \\\\ W^{(1)} &= \\begin{bmatrix}3 & 1\\end{bmatrix},  &b^{(1)}&=-10\\end{align}$$\n",
    "\n",
    "For a training example with features $x = \\begin{bmatrix}3 \\\\-2 \\\\ 2\\end{bmatrix}$ what are the values in this network of $x^{(1)}$ and $\\hat{y}$? Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0(b)\n",
    "rubric={reasoning:10}\n",
    "\n",
    "Draw this neural network using a circle/arrow diagram. Label the diagram with the weight/bias values given above. \n",
    "\n",
    "If you want to draw this diagram by hand, that is fine: you can take a photo of the drawing and put it in here. If you are doing so, make sure you upload the image to your repo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0(c)\n",
    "rubric={accuracy:3,quality:3}\n",
    "\n",
    "For optimization purposes, the parameters above would typically be combined into a single parameter vector, for example:\n",
    "\n",
    "$$w_\\text{all} = \\begin{bmatrix}W^{(0)}_\\text{flattened}\\\\ b^{(0)} \\\\ W^{(1)}_\\text{flattened} \\\\ b^{(1)}\\end{bmatrix} = \\begin{bmatrix}-2\\\\2\\\\-1\\\\-1\\\\-2\\\\0\\\\2\\\\0\\\\3\\\\1\\\\-10\\end{bmatrix}$$\n",
    "\n",
    "The reason for this is that optimization functions, like `scipy.optimize.minimize` or the `gradient_descent` and `stochastic_gradient_descent` functions you've written, generally all tend to assume that the input is a 1D numpy array. They would not work if you fed in, say, a list of lists of arrays.\n",
    "\n",
    "Your task: write a python function `combine_params` that takes in a list of weights and a list of biases, and returns the flattened vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0 = np.array([[-2,2,-1],[-1,-2,0]])\n",
    "b0 = np.array([2,0])\n",
    "W1 = np.array([3,1])\n",
    "b1 = np.array([-10])\n",
    "\n",
    "all_params = [W0, b0, W1, b1]\n",
    "all_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_answer = combine_params(all_params)\n",
    "desired_answer = np.array([-2, 2, -1, -1, -2, 0, 2, 0, 3, 1, -10])\n",
    "\n",
    "assert np.array_equal(my_answer, desired_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: digits warm-up\n",
    "\n",
    "The code below loads scikit-learn's built-in handwritten digits dataset and fits the following classifiers:\n",
    "\n",
    "- KNN\n",
    "- random forest\n",
    "- RBF SVM\n",
    "- logistic regression\n",
    "- 1-hidden-layer neural network using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X, y = digits['data'], digits['target']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1)\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'valid samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'knn'           : KNeighborsClassifier(),\n",
    "    'random forest' : RandomForestClassifier(n_estimators=50),\n",
    "    'SVM'           : SVC(C=100, gamma=\"scale\"),\n",
    "    'logistic reg'  : LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\"),\n",
    "    'sklearn NN'    : MLPClassifier() \n",
    "}\n",
    "\n",
    "train_scores = dict()\n",
    "valid_scores = dict()\n",
    "training_times = dict()\n",
    "\n",
    "for classifier_name, classifier_obj in classifiers.items():\n",
    "    print(\"Fitting\", classifier_name)\n",
    "    t = time.time()\n",
    "    classifier_obj.fit(X_train, y_train)\n",
    "    \n",
    "    training_times[classifier_name] = time.time() - t\n",
    "    train_scores[classifier_name] = classifier_obj.score(X_train, y_train)\n",
    "    valid_scores[classifier_name] = classifier_obj.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format # make things look prettier when printing\n",
    "data = {\"train acc\": train_scores, \"valid acc\" : valid_scores, \"training time (s)\" : training_times}\n",
    "df = pd.DataFrame(data, columns=data.keys())\n",
    "df.index = list(classifiers.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this dataset isn't very exciting in the sense that most of the methods get a high test accuracy after very little time. We'll use this dataset for a few more moments, and then move onto another one soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(a)\n",
    "rubric={accuracy:5}\n",
    "\n",
    "Using Keras, create a neural network with the same architecture as the sklearn NN above. You should one-hot encode the labels using `tensorflow.keras.utils.to_categorical` (although this step can be skipped by using [KerasClasifier](https://www.tensorflow.org/api_docs/python/tf/keras/wrappers/scikit_learn/KerasClassifier), we'll avoid using that here). Briefly discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(b)\n",
    "rubric={viz:5}\n",
    "\n",
    "For the same network above, make the following two plots:\n",
    "\n",
    "1. A plot of accuracy vs. optimization epochs. You should have two curves on this plot, one of train and one for test.\n",
    "2. A plot of the loss vs. optimization epochs. You should have two curves on this plot, one of train and one for test.\n",
    "\n",
    "Some notes:\n",
    "\n",
    "- To get access to this information, you can use the history object that is returned by `fit`. \n",
    "- If you're wondering what the difference is, accuracy is the percentage of examples that are correctles classified (always between $0$ and $1$), whereas the loss is literally the function being optimized (like `loss_lr` in lab 1, not necessarily between $0$ and $1$). The loss can't just be the number of incorrectly classifier examples, since this isn't a continuous function and would be too hard to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c)\n",
    "rubric={reasoning:5,quality:5}\n",
    "\n",
    "The optimization problem of training a neural network is non-convex. To explore this, try training\n",
    "your network several times. You will get different results due to different random initializations and different randomness in the optimization method itself. Explore how the training/validation error changes across\n",
    "runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 1(d) \n",
    "rubric={reasoning:1}\n",
    "\n",
    "Continuing with the above, try also exploring how the model parameters themselves (the weights) change across runs (you'll need to think of a reasonable way of comparing the weights of two networks).\n",
    "Do you observe substantially different weight sets all with a similar prediction accuracy... or something different?\n",
    "\n",
    "Note: to inspect the weights themselves, use the `get_weights()` function for the Keras model/layer object. Also, you can use your `combine_params` function from Exercise 0 if you push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: big digits\n",
    "\n",
    "Next, we'll move on to the famous the MNIST digits -- a classic dataset for deep learning. The MNIST data set is  bigger than the digits dataset built into sklearn: the images are larger ($28\\times28$ instead of $8\\times8$) and there are more of them ($70000$ insetad of $1797$). In total, we're dealing with $70000\\times28\\times28\\approx 55$ million training pixels instead of $1797\\times8\\times8\\approx80000$ training pixels (about $500$ times more data). \n",
    "\n",
    "If you're interested, check out [this site](http://yann.lecun.com/exdb/mnist/) showing the progress on this dataset from 1998 to 2012. \n",
    "\n",
    "The following code loads the MNIST dataset. The first time you run it, the data will be downloaded. In future times, it will use the local version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train_img, y_train), (X_test_img, y_test) = tensorflow.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a random training example\n",
    "i = np.random.randint(0,len(X_train_img))\n",
    "plt.imshow(X_train_img[i],cmap='gray')\n",
    "plt.title('This is a %d' % y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_img.reshape(60000, 28*28)\n",
    "X_test = X_test_img.reshape(10000, 28*28)\n",
    "X_train = X_train / 255 # this is the same a scaling, since the pixel intensities range from 0 to 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a)\n",
    "rubric={reasoning:15}\n",
    "\n",
    "1. Which of the classifiers from Exercise 1 scale well to this larger data set? You are free to make arguments using theory (big-O running times) and/or experiment (timed runs) as you see fit. Keep in mind that we've increased both $n$ (number of examples) and $d$ (number of features). Don't subject yourself to experiments that take tens of minutes or hours. It is fine to declare defeat after a couple of minutes and say that a method doesn't scale. But, when that happens, try to say a little bit about why that might be the case. \n",
    "2. For those methods where the running time is reasonable (say, a couple minutes of computation), how does the accuracy compare between the methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b)\n",
    "rubric={reasoning:15}\n",
    "\n",
    "The code below runs a bigger Keras model on the full MNIST data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = utils.to_categorical(y_train, num_classes)\n",
    "Y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "elapsed_time = time.time()-start_time\n",
    "print(\"---Running Time: %s seconds ---\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the neural network implemented with Keras above, explore the effects of the different hyperparameters on accuracy. Try at least 3 variations on what you're given above. In each case, briefly discuss your results. Some things you can consider trying:\n",
    "  - adding/removing layer(s)\n",
    "  - changing the [activation functions](https://keras.io/activations/) from `relu` to `tanh`\n",
    "  - adding [regularization](https://keras.io/regularizers/) such as dropout\n",
    "  - changing the way the weights are [initialized](https://keras.io/initializations/)\n",
    "  - changing the [optimizer](https://keras.io/optimizers/) from adam to something else, like SGD. Read the documentation and try changing the _hyperparameters of the optimizer_ in addition to just the type of optimizer (e.g., $\\alpha$ in gradient descent is a hyperparameter of the optimizer). It should not be difficult to completely mess up your training procedure, for example by tampering with the learning rate.\n",
    "\n",
    "**NOTE: if at any point things are just way too slow, you can use a subset of the data to speed things up. But try to still draw interesting conclusions to the extent possible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: pondering neural networks\n",
    "rubric={writing:5}\n",
    "\n",
    "The above writing marks are allocated to the overall writing quality of your answers below to the sub-parts of Exercise 3. For each question, no need to write more than 3 sentences. You may also include some code / code output in your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(a)\n",
    "rubric={reasoning:3}\n",
    "\n",
    "Explain why a 1-layer (zero-hidden-layer) neural network with a linear activation is equivalent to linear regression. If you just wanted to do linear regression, what are the disadvantages of using Keras instead of a package like R's `lm`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(b)\n",
    "rubric={reasoning:3}\n",
    "\n",
    "Consider a regression problem with $d=500$ features. You use a 2-hidden-layer neural network with hidden layer sizes $100$ and $200$. How many parameters does the model have? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(c)\n",
    "rubric={reasoning:3}\n",
    "\n",
    "Hyperparameter optimization would be easy if we could independently tune each hyperparameter. Then, with $m$ hyperparameters, we'd just have $m$ one-dimensional optimization problems. However, in reality the hyperparameters interact, which leaves you with the more daunting $m$-dimensional optimization problem. Consider for example a regularization hyperparameter (like dropout) and an architecture parameter (like the number of units or layers). Why do you think these hyperparameters would \"interact\" with each other? For example, if the regularization strength was very large, would you expect bigger or smaller networks to perform well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(d)\n",
    "rubric={reasoning:3}\n",
    "\n",
    "If you look at the [documentation for scikit-learn's neural network classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), you'll see that the user only needs to input the sizes of the hidden layers; like other scikit-learn classifiers, there's no need for the user to explicitly enter the number of features when creating the model object. However, Keras requires us to set the `input_dim` argument in the first `Dense` layer, which specifies the number of features. Why do you think Keras requires this whereas scikit-learn doesn't?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Exercise 4(a)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "It should be the case that logistic regression is equivalent to a neural network with no hidden layers. \n",
    "\n",
    "Using sklearn's `MLPClassifier`, fit a zero-hidden-layer neural network on the synthetic 2D data (generated below) and compare the learned weights to what you get with `LogisticRegression`. Do you get essentially the same model with the neural network? You'll need to fiddle with the hyperparameters (optimization, regularization) to get something equivalent. \n",
    "\n",
    "If you want to be very careful, see if you can get the coefficients to be exactly the same up to several decimal places (I managed to do this).  However, this might not be a good use of your time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "d = 2\n",
    "np.random.seed(123)\n",
    "X = np.random.rand(n,2)\n",
    "y = np.random.rand(n) > 0.7\n",
    "X[y==0,0] += .7\n",
    "X[y==0,1] += .3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Exercise 4(b)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Can you get this working with Keras as well? I tried for about 20 minutes and wasn't successful (speaking of questionable uses of time...), so if you figure it out please send me a message and I'll add your solution to the official solutions. Some reasons why this is annoying:\n",
    "\n",
    "- One has to be very careful with the (L2) regularization. The interpretation of the regularization strength may vary across packages. It might be easier to turn off regularization for both.\n",
    "- It's not clear whether to use a `softmax` activation + `categorical_crossentropy` loss + one-hot enoded labels or `sigmoid` activation + `binary_crossentropy` loss + regular labels. I have slightly more faith in the former approach. For this reason, it might be easier to first try and get this working with linear regression, and then move on to logistic.\n",
    "- The SGD-based optimizers available in Keras aren't well suited to this kind of toy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Exercise 5: backprop\n",
    "rubric={reasoning:1}\n",
    "\n",
    "From scratch using only raw numpy, implement a one-hidden-layer neural network for regression using ReLUs. Show your computation of the gradients alongside the code. You can ignore the fact that the ReLU function is not differentiable when its input equals zero.\n",
    "\n",
    "Note: there are probably a lot of resources out there where people give their \"raw\" neural network implementations. If you're going to do this and you consult any sources, make sure you cite them. \n",
    "\n",
    "Note: this is a lot more work than most optional questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
