

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>DSCI 572 Lab 3 &#8212; DSCI 572 Supervised Learning II</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'labs/lab3/lab3';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mds-hex-sticker.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/mds-hex-sticker.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../lectures/01_floating-point-numbers.html">Lecture 1: Floating-Point Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/02_gradient-descent.html">Lecture 2: Optimization &amp; Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/03_sgd-intro-to-nn.html">Lecture 3: Stochastic Gradient Descent and Introduction to Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/04_pytorch-neural-networks-pt1.html">Lecture 4: Introduction to Pytorch &amp; Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/05_neural-networks-pt2.html">Lecture 5: Training Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/06_cnns-pt1.html">Lecture 6: Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/07_cnns-pt2.html">Lecture 7: CNNs in Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/08_advanced-deep-learning.html">Lecture 8: Advanced Convolutional Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../lectures/appendixA_gradients.html">Appendix A: Gradients Review</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/appendixB_logistic-loss.html">Appendix B: Logistic Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/appendixC_computing-derivatives.html">Appendix C: Computing Derivatives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/appendixD_bitmoji-CNN.html">Appendix D: Creating a CNN to Predict Bitmojis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Attribution</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../LICENSE.html">LICENSE</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/UBC-MDS/DSCI_572_sup-learn-2" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/labs/lab3/lab3.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>DSCI 572 Lab 3</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installations">Installations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructions">Instructions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-0-neural-networks-by-hand">Exercise 0: neural networks “by hand”</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a">0(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b">0(b)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c">0(c)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-digits-warm-up">Exercise 1: digits warm-up</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">1(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1(b)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">1(c)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-1-d">(optional) 1(d)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-big-digits">Exercise 2: big digits</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2(b)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-pondering-neural-networks">Exercise 3: pondering neural networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">3(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">3(b)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">3(c)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d">3(d)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercise-4-a">(optional) Exercise 4(a)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercise-4-b">(optional) Exercise 4(b)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercise-5-backprop">(optional) Exercise 5: backprop</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="dsci-572-lab-3">
<h1>DSCI 572 Lab 3<a class="headerlink" href="#dsci-572-lab-3" title="Permalink to this heading">#</a></h1>
<section id="installations">
<h2>Installations<a class="headerlink" href="#installations" title="Permalink to this heading">#</a></h2>
<p>You’ll first need to install TensorFlow, which should be possible with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">tensorflow</span>
</pre></div>
</div>
<p>Note that we will be using TensorFlow 2. If you had TensorFlow 1 installed previously, you may need to remove it or upgrade.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">__version__</span> <span class="c1"># should print 2.0.0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;2.0.0&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># keras imports</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.wrappers.scikit_learn</span> <span class="kn">import</span> <span class="n">KerasClassifier</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.datasets</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># other imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span><span class="p">,</span> <span class="n">MLPRegressor</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">time</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">16</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="instructions">
<h2>Instructions<a class="headerlink" href="#instructions" title="Permalink to this heading">#</a></h2>
<p>rubric={mechanics:10}</p>
<p>Follow the <a class="reference external" href="https://ubc-mds.github.io/resources_pages/general_lab_instructions/">general lab instructions</a>.</p>
</section>
<section id="exercise-0-neural-networks-by-hand">
<h2>Exercise 0: neural networks “by hand”<a class="headerlink" href="#exercise-0-neural-networks-by-hand" title="Permalink to this heading">#</a></h2>
<section id="a">
<h3>0(a)<a class="headerlink" href="#a" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:10}</p>
<p>Suppose that we use a neural network with one hidden layer and ReLU activations for a regression problem. After training, we obtain the following parameters:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}W^{(0)} &amp;= \begin{bmatrix}-2 &amp; 2 &amp; -1\\-1 &amp; -2 &amp; 0\end{bmatrix},  &amp;b^{(0)}&amp;=\begin{bmatrix}2 \\ 0\end{bmatrix} \\ W^{(1)} &amp;= \begin{bmatrix}3 &amp; 1\end{bmatrix},  &amp;b^{(1)}&amp;=-10\end{align}\end{split}\]</div>
<p>For a training example with features <span class="math notranslate nohighlight">\(x = \begin{bmatrix}3 \\-2 \\ 2\end{bmatrix}\)</span> what are the values in this network of <span class="math notranslate nohighlight">\(x^{(1)}\)</span> and <span class="math notranslate nohighlight">\(\hat{y}\)</span>? Show your work.</p>
</section>
<section id="b">
<h3>0(b)<a class="headerlink" href="#b" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:10}</p>
<p>Draw this neural network using a circle/arrow diagram. Label the diagram with the weight/bias values given above.</p>
<p>If you want to draw this diagram by hand, that is fine: you can take a photo of the drawing and put it in here. If you are doing so, make sure you upload the image to your repo!</p>
</section>
<section id="c">
<h3>0(c)<a class="headerlink" href="#c" title="Permalink to this heading">#</a></h3>
<p>rubric={accuracy:3,quality:3}</p>
<p>For optimization purposes, the parameters above would typically be combined into a single parameter vector, for example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}w_\text{all} = \begin{bmatrix}W^{(0)}_\text{flattened}\\ b^{(0)} \\ W^{(1)}_\text{flattened} \\ b^{(1)}\end{bmatrix} = \begin{bmatrix}-2\\2\\-1\\-1\\-2\\0\\2\\0\\3\\1\\-10\end{bmatrix}\end{split}\]</div>
<p>The reason for this is that optimization functions, like <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code> or the <code class="docutils literal notranslate"><span class="pre">gradient_descent</span></code> and <code class="docutils literal notranslate"><span class="pre">stochastic_gradient_descent</span></code> functions you’ve written, generally all tend to assume that the input is a 1D numpy array. They would not work if you fed in, say, a list of lists of arrays.</p>
<p>Your task: write a python function <code class="docutils literal notranslate"><span class="pre">combine_params</span></code> that takes in a list of weights and a list of biases, and returns the flattened vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">W0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">])</span>

<span class="n">all_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W0</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">]</span>
<span class="n">all_params</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_answer</span> <span class="o">=</span> <span class="n">combine_params</span><span class="p">(</span><span class="n">all_params</span><span class="p">)</span>
<span class="n">desired_answer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">])</span>

<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">my_answer</span><span class="p">,</span> <span class="n">desired_answer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="exercise-1-digits-warm-up">
<h2>Exercise 1: digits warm-up<a class="headerlink" href="#exercise-1-digits-warm-up" title="Permalink to this heading">#</a></h2>
<p>The code below loads scikit-learn’s built-in handwritten digits dataset and fits the following classifiers:</p>
<ul class="simple">
<li><p>KNN</p></li>
<li><p>random forest</p></li>
<li><p>RBF SVM</p></li>
<li><p>logistic regression</p></li>
<li><p>1-hidden-layer neural network using sklearn</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">digits</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;train samples&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;valid samples&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifiers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;knn&#39;</span>           <span class="p">:</span> <span class="n">KNeighborsClassifier</span><span class="p">(),</span>
    <span class="s1">&#39;random forest&#39;</span> <span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span>
    <span class="s1">&#39;SVM&#39;</span>           <span class="p">:</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="s2">&quot;scale&quot;</span><span class="p">),</span>
    <span class="s1">&#39;logistic reg&#39;</span>  <span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">),</span>
    <span class="s1">&#39;sklearn NN&#39;</span>    <span class="p">:</span> <span class="n">MLPClassifier</span><span class="p">()</span> 
<span class="p">}</span>

<span class="n">train_scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">valid_scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">training_times</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">classifier_name</span><span class="p">,</span> <span class="n">classifier_obj</span> <span class="ow">in</span> <span class="n">classifiers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fitting&quot;</span><span class="p">,</span> <span class="n">classifier_name</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">classifier_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="n">training_times</span><span class="p">[</span><span class="n">classifier_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span>
    <span class="n">train_scores</span><span class="p">[</span><span class="n">classifier_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">classifier_obj</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">valid_scores</span><span class="p">[</span><span class="n">classifier_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">classifier_obj</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{:,.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span> <span class="c1"># make things look prettier when printing</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;train acc&quot;</span><span class="p">:</span> <span class="n">train_scores</span><span class="p">,</span> <span class="s2">&quot;valid acc&quot;</span> <span class="p">:</span> <span class="n">valid_scores</span><span class="p">,</span> <span class="s2">&quot;training time (s)&quot;</span> <span class="p">:</span> <span class="n">training_times</span><span class="p">}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">classifiers</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<p>As you can see, this dataset isn’t very exciting in the sense that most of the methods get a high test accuracy after very little time. We’ll use this dataset for a few more moments, and then move onto another one soon.</p>
<section id="id1">
<h3>1(a)<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>rubric={accuracy:5}</p>
<p>Using Keras, create a neural network with the same architecture as the sklearn NN above. You should one-hot encode the labels using <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.utils.to_categorical</span></code> (although this step can be skipped by using <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/wrappers/scikit_learn/KerasClassifier">KerasClasifier</a>, we’ll avoid using that here). Briefly discuss your results.</p>
</section>
<section id="id2">
<h3>1(b)<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>rubric={viz:5}</p>
<p>For the same network above, make the following two plots:</p>
<ol class="arabic simple">
<li><p>A plot of accuracy vs. optimization epochs. You should have two curves on this plot, one of train and one for test.</p></li>
<li><p>A plot of the loss vs. optimization epochs. You should have two curves on this plot, one of train and one for test.</p></li>
</ol>
<p>Some notes:</p>
<ul class="simple">
<li><p>To get access to this information, you can use the history object that is returned by <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
<li><p>If you’re wondering what the difference is, accuracy is the percentage of examples that are correctles classified (always between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>), whereas the loss is literally the function being optimized (like <code class="docutils literal notranslate"><span class="pre">loss_lr</span></code> in lab 1, not necessarily between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>). The loss can’t just be the number of incorrectly classifier examples, since this isn’t a continuous function and would be too hard to optimize.</p></li>
</ul>
</section>
<section id="id3">
<h3>1(c)<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:5,quality:5}</p>
<p>The optimization problem of training a neural network is non-convex. To explore this, try training
your network several times. You will get different results due to different random initializations and different randomness in the optimization method itself. Explore how the training/validation error changes across
runs.</p>
</section>
<section id="optional-1-d">
<h3>(optional) 1(d)<a class="headerlink" href="#optional-1-d" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:1}</p>
<p>Continuing with the above, try also exploring how the model parameters themselves (the weights) change across runs (you’ll need to think of a reasonable way of comparing the weights of two networks).
Do you observe substantially different weight sets all with a similar prediction accuracy… or something different?</p>
<p>Note: to inspect the weights themselves, use the <code class="docutils literal notranslate"><span class="pre">get_weights()</span></code> function for the Keras model/layer object. Also, you can use your <code class="docutils literal notranslate"><span class="pre">combine_params</span></code> function from Exercise 0 if you push.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="exercise-2-big-digits">
<h2>Exercise 2: big digits<a class="headerlink" href="#exercise-2-big-digits" title="Permalink to this heading">#</a></h2>
<p>Next, we’ll move on to the famous the MNIST digits – a classic dataset for deep learning. The MNIST data set is  bigger than the digits dataset built into sklearn: the images are larger (<span class="math notranslate nohighlight">\(28\times28\)</span> instead of <span class="math notranslate nohighlight">\(8\times8\)</span>) and there are more of them (<span class="math notranslate nohighlight">\(70000\)</span> insetad of <span class="math notranslate nohighlight">\(1797\)</span>). In total, we’re dealing with <span class="math notranslate nohighlight">\(70000\times28\times28\approx 55\)</span> million training pixels instead of <span class="math notranslate nohighlight">\(1797\times8\times8\approx80000\)</span> training pixels (about <span class="math notranslate nohighlight">\(500\)</span> times more data).</p>
<p>If you’re interested, check out <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">this site</a> showing the progress on this dataset from 1998 to 2012.</p>
<p>The following code loads the MNIST dataset. The first time you run it, the data will be downloaded. In future times, it will use the local version.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the data, shuffled and split between train and test sets</span>
<span class="p">(</span><span class="n">X_train_img</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test_img</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_img</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(60000, 28, 28)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># display a random training example</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_img</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train_img</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;This is a </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/8460e9b7bdfd67fd4caf4df0b22d0d9dc07a476952f5a5cfb923a410516418aa.png" src="../../_images/8460e9b7bdfd67fd4caf4df0b22d0d9dc07a476952f5a5cfb923a410516418aa.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test_img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span> <span class="o">/</span> <span class="mi">255</span> <span class="c1"># this is the same a scaling, since the pixel intensities range from 0 to 255</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;train samples&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;test samples&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>60000 train samples
10000 test samples
</pre></div>
</div>
</div>
</div>
<section id="id4">
<h3>2(a)<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:15}</p>
<ol class="arabic simple">
<li><p>Which of the classifiers from Exercise 1 scale well to this larger data set? You are free to make arguments using theory (big-O running times) and/or experiment (timed runs) as you see fit. Keep in mind that we’ve increased both <span class="math notranslate nohighlight">\(n\)</span> (number of examples) and <span class="math notranslate nohighlight">\(d\)</span> (number of features). Don’t subject yourself to experiments that take tens of minutes or hours. It is fine to declare defeat after a couple of minutes and say that a method doesn’t scale. But, when that happens, try to say a little bit about why that might be the case.</p></li>
<li><p>For those methods where the running time is reasonable (say, a couple minutes of computation), how does the accuracy compare between the methods?</p></li>
</ol>
</section>
<section id="id5">
<h3>2(b)<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:15}</p>
<p>The code below runs a bigger Keras model on the full MNIST data set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># convert class vectors to binary class matrices</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---Running Time: </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="n">elapsed_time</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For the neural network implemented with Keras above, explore the effects of the different hyperparameters on accuracy. Try at least 3 variations on what you’re given above. In each case, briefly discuss your results. Some things you can consider trying:</p>
<ul class="simple">
<li><p>adding/removing layer(s)</p></li>
<li><p>changing the <a class="reference external" href="https://keras.io/activations/">activation functions</a> from <code class="docutils literal notranslate"><span class="pre">relu</span></code> to <code class="docutils literal notranslate"><span class="pre">tanh</span></code></p></li>
<li><p>adding <a class="reference external" href="https://keras.io/regularizers/">regularization</a> such as dropout</p></li>
<li><p>changing the way the weights are <a class="reference external" href="https://keras.io/initializations/">initialized</a></p></li>
<li><p>changing the <a class="reference external" href="https://keras.io/optimizers/">optimizer</a> from adam to something else, like SGD. Read the documentation and try changing the <em>hyperparameters of the optimizer</em> in addition to just the type of optimizer (e.g., <span class="math notranslate nohighlight">\(\alpha\)</span> in gradient descent is a hyperparameter of the optimizer). It should not be difficult to completely mess up your training procedure, for example by tampering with the learning rate.</p></li>
</ul>
<p><strong>NOTE: if at any point things are just way too slow, you can use a subset of the data to speed things up. But try to still draw interesting conclusions to the extent possible.</strong></p>
</section>
</section>
<section id="exercise-3-pondering-neural-networks">
<h2>Exercise 3: pondering neural networks<a class="headerlink" href="#exercise-3-pondering-neural-networks" title="Permalink to this heading">#</a></h2>
<p>rubric={writing:5}</p>
<p>The above writing marks are allocated to the overall writing quality of your answers below to the sub-parts of Exercise 3. For each question, no need to write more than 3 sentences. You may also include some code / code output in your answers.</p>
<section id="id6">
<h3>3(a)<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:3}</p>
<p>Explain why a 1-layer (zero-hidden-layer) neural network with a linear activation is equivalent to linear regression. If you just wanted to do linear regression, what are the disadvantages of using Keras instead of a package like R’s <code class="docutils literal notranslate"><span class="pre">lm</span></code>?</p>
</section>
<section id="id7">
<h3>3(b)<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:3}</p>
<p>Consider a regression problem with <span class="math notranslate nohighlight">\(d=500\)</span> features. You use a 2-hidden-layer neural network with hidden layer sizes <span class="math notranslate nohighlight">\(100\)</span> and <span class="math notranslate nohighlight">\(200\)</span>. How many parameters does the model have? Justify your answer.</p>
</section>
<section id="id8">
<h3>3(c)<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:3}</p>
<p>Hyperparameter optimization would be easy if we could independently tune each hyperparameter. Then, with <span class="math notranslate nohighlight">\(m\)</span> hyperparameters, we’d just have <span class="math notranslate nohighlight">\(m\)</span> one-dimensional optimization problems. However, in reality the hyperparameters interact, which leaves you with the more daunting <span class="math notranslate nohighlight">\(m\)</span>-dimensional optimization problem. Consider for example a regularization hyperparameter (like dropout) and an architecture parameter (like the number of units or layers). Why do you think these hyperparameters would “interact” with each other? For example, if the regularization strength was very large, would you expect bigger or smaller networks to perform well?</p>
</section>
<section id="d">
<h3>3(d)<a class="headerlink" href="#d" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:3}</p>
<p>If you look at the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">documentation for scikit-learn’s neural network classifier</a>, you’ll see that the user only needs to input the sizes of the hidden layers; like other scikit-learn classifiers, there’s no need for the user to explicitly enter the number of features when creating the model object. However, Keras requires us to set the <code class="docutils literal notranslate"><span class="pre">input_dim</span></code> argument in the first <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layer, which specifies the number of features. Why do you think Keras requires this whereas scikit-learn doesn’t?</p>
</section>
</section>
<section id="optional-exercise-4-a">
<h2>(optional) Exercise 4(a)<a class="headerlink" href="#optional-exercise-4-a" title="Permalink to this heading">#</a></h2>
<p>rubric={reasoning:1}</p>
<p>It should be the case that logistic regression is equivalent to a neural network with no hidden layers.</p>
<p>Using sklearn’s <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span></code>, fit a zero-hidden-layer neural network on the synthetic 2D data (generated below) and compare the learned weights to what you get with <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>. Do you get essentially the same model with the neural network? You’ll need to fiddle with the hyperparameters (optimization, regularization) to get something equivalent.</p>
<p>If you want to be very careful, see if you can get the coefficients to be exactly the same up to several decimal places (I managed to do this).  However, this might not be a good use of your time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.7</span>
<span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">.7</span>
<span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">.3</span>
</pre></div>
</div>
</div>
</div>
<section id="optional-exercise-4-b">
<h3>(optional) Exercise 4(b)<a class="headerlink" href="#optional-exercise-4-b" title="Permalink to this heading">#</a></h3>
<p>rubric={reasoning:1}</p>
<p>Can you get this working with Keras as well? I tried for about 20 minutes and wasn’t successful (speaking of questionable uses of time…), so if you figure it out please send me a message and I’ll add your solution to the official solutions. Some reasons why this is annoying:</p>
<ul class="simple">
<li><p>One has to be very careful with the (L2) regularization. The interpretation of the regularization strength may vary across packages. It might be easier to turn off regularization for both.</p></li>
<li><p>It’s not clear whether to use a <code class="docutils literal notranslate"><span class="pre">softmax</span></code> activation + <code class="docutils literal notranslate"><span class="pre">categorical_crossentropy</span></code> loss + one-hot enoded labels or <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> activation + <code class="docutils literal notranslate"><span class="pre">binary_crossentropy</span></code> loss + regular labels. I have slightly more faith in the former approach. For this reason, it might be easier to first try and get this working with linear regression, and then move on to logistic.</p></li>
<li><p>The SGD-based optimizers available in Keras aren’t well suited to this kind of toy dataset.</p></li>
</ul>
</section>
</section>
<section id="optional-exercise-5-backprop">
<h2>(optional) Exercise 5: backprop<a class="headerlink" href="#optional-exercise-5-backprop" title="Permalink to this heading">#</a></h2>
<p>rubric={reasoning:1}</p>
<p>From scratch using only raw numpy, implement a one-hidden-layer neural network for regression using ReLUs. Show your computation of the gradients alongside the code. You can ignore the fact that the ReLU function is not differentiable when its input equals zero.</p>
<p>Note: there are probably a lot of resources out there where people give their “raw” neural network implementations. If you’re going to do this and you consult any sources, make sure you cite them.</p>
<p>Note: this is a lot more work than most optional questions.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./labs/lab3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installations">Installations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructions">Instructions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-0-neural-networks-by-hand">Exercise 0: neural networks “by hand”</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a">0(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b">0(b)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c">0(c)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-digits-warm-up">Exercise 1: digits warm-up</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">1(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1(b)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">1(c)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-1-d">(optional) 1(d)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-big-digits">Exercise 2: big digits</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2(b)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-pondering-neural-networks">Exercise 3: pondering neural networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">3(a)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">3(b)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">3(c)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d">3(d)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercise-4-a">(optional) Exercise 4(a)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercise-4-b">(optional) Exercise 4(b)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercise-5-backprop">(optional) Exercise 5: backprop</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varada Kolhatkar
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>